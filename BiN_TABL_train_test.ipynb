{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-PVsZeWjCiw"
      },
      "source": [
        "### **BiN-TABL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVPONVeVw0nh"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm \n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNdy1u5zjMaw"
      },
      "source": [
        "### **Data**\n",
        "The dataset used is the LI-2010 dataset. \n",
        "\n",
        "As in the original paper I used the first 7 days to train and to validate, and the rest 3 days to do the the testing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls5u0jngxkjl"
      },
      "outputs": [],
      "source": [
        "# please change the data_path to your local path and download the free dataset\n",
        "\n",
        "dec_data = np.loadtxt('/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
        "dec_train = dec_data[:, :int(dec_data.shape[1] * 0.8)]\n",
        "dec_val = dec_data[:, int(dec_data.shape[1] * 0.8):]\n",
        "\n",
        "dec_test1 = np.loadtxt('/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_DecPre_CF_7.txt')\n",
        "dec_test2 = np.loadtxt('/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_DecPre_CF_8.txt')\n",
        "dec_test3 = np.loadtxt('/published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_DecPre_CF_9.txt')\n",
        "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
        "\n",
        "h = 2        \n",
        "dim = 10\n",
        "\n",
        "y_train = dec_train[-h, :].flatten()\n",
        "y_val = dec_val[-h, :].flatten()\n",
        "y_test = dec_test[-h, :].flatten()\n",
        "\n",
        "y_train = y_train[dim-1:] - 1\n",
        "y_val = y_val[dim-1:] - 1\n",
        "y_test = y_test[dim-1:] - 1 \n",
        "\n",
        "dec_train = dec_train[:40, :].T\n",
        "dec_val = dec_val[:40, :].T\n",
        "dec_test = dec_test[:40, :].T\n",
        "\n",
        "print(dec_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Computing weights for the weighted cross entropy loss\n",
        "def compute_weights(y):\n",
        "  cont_0 = 0\n",
        "  cont_1 = 0\n",
        "  cont_2 = 0\n",
        "  for i in range(y.shape[0]):\n",
        "    if (y[i] == 0):\n",
        "      cont_0 += 1\n",
        "    elif (y[i] == 1):\n",
        "      cont_1 += 1\n",
        "    elif (y[i] == 2):\n",
        "      cont_2 += 2\n",
        "    else: \n",
        "      raise Exception(\"wrong labels\")\n",
        "  return torch.Tensor([1e6/cont_0, 1e6/cont_1, 1e6/cont_2]).to(device)\n",
        "\n",
        "y_total = np.concatenate((y_train, y_val, y_test))\n",
        "weights = compute_weights(y_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x7PAu1LySOZ"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
        "    def __init__(self, x, y, num_classes, dim):\n",
        "        \"\"\"Initialization\"\"\" \n",
        "        self.num_classes = num_classes\n",
        "        self.dim = dim\n",
        "        self.x = x   \n",
        "        self.y = y\n",
        "\n",
        "        self.length = x.shape[0] - (T/10) -self.dim + 1\n",
        "        print(self.length)\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        self.x = torch.unsqueeze(x, 1)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the total number of samples\"\"\"\n",
        "        return int(self.length)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        input = self.x[i:i+self.dim, :]\n",
        "        input = input.permute(1, 2, 0)\n",
        "        input = torch.squeeze(input)\n",
        "\n",
        "        return input, self.y[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ndByE-Ajmq8",
        "outputId": "9158a184-f349-4fbb-8f82-74b379561ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50936.0\n",
            "139573.0\n",
            "203786.0\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameters\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 100\n",
        "T = 50   #horizon    \n",
        "lr = 0.001\n",
        "num_classes = 3\n",
        "\n",
        "dataset_val = Dataset(dec_val, y_val, num_classes, dim)\n",
        "dataset_test = Dataset(dec_test, y_test, num_classes, dim)\n",
        "dataset_train = Dataset(dec_train, y_train, num_classes, dim)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEIIi2NwjtgC"
      },
      "source": [
        "### **Model Architecture**\n",
        "The architecture is explained in the original paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhA2p2kcUj2q"
      },
      "outputs": [],
      "source": [
        "class TABL_layer(nn.Module):\n",
        "    def __init__(self, d2, d1, t1, t2):\n",
        "        super().__init__()\n",
        "        self.t1 = t1\n",
        "\n",
        "        weight = torch.Tensor(d2, d1)\n",
        "        self.W1 = nn.Parameter(weight)\n",
        "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
        "        \n",
        "        weight2 = torch.Tensor(t1, t1)\n",
        "        self.W = nn.Parameter(weight2)\n",
        "        nn.init.constant_(self.W, 1/t1)\n",
        " \n",
        "        weight3 = torch.Tensor(t1, t2)\n",
        "        self.W2 = nn.Parameter(weight3)\n",
        "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
        "\n",
        "        bias1 = torch.Tensor(d2, t2)\n",
        "        self.B = nn.Parameter(bias1)\n",
        "        nn.init.constant_(self.B, 0)\n",
        "\n",
        "        l = torch.Tensor(1,)\n",
        "        self.l = nn.Parameter(l)\n",
        "        nn.init.constant_(self.l, 0.5)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, X):\n",
        "        \n",
        "        #maintaining the weight parameter between 0 and 1.\n",
        "        if (self.l[0] < 0): \n",
        "          l = torch.Tensor(1,).to(device)\n",
        "          self.l = nn.Parameter(l)\n",
        "          nn.init.constant_(self.l, 0.0)\n",
        "\n",
        "        if (self.l[0] > 1): \n",
        "          l = torch.Tensor(1,).to(device)\n",
        "          self.l = nn.Parameter(l)\n",
        "          nn.init.constant_(self.l, 1.0)\n",
        "     \n",
        "        #modelling the dependence along the first mode of X while keeping the temporal order intact (7)\n",
        "        X = self.W1 @ X\n",
        "\n",
        "        #enforcing constant (1) on the diagonal\n",
        "        W = self.W -self.W *torch.eye(self.t1,dtype=torch.float32).to(device)+torch.eye(self.t1,dtype=torch.float32).to(device)/self.t1\n",
        "\n",
        "        #attention, the aim of the second step is to learn how important the temporal instances are to each other (8)\n",
        "        E = X @ W\n",
        "\n",
        "        #computing the attention mask  (9)\n",
        "        A = torch.softmax(E, dim=-1)\n",
        "\n",
        "        #applying a soft attention mechanism  (10)\n",
        "        #he attention mask A obtained from the third step is used to zero out the effect of unimportant elements\n",
        "        X = self.l[0] * (X) + (1.0 - self.l[0])*X*A\n",
        "\n",
        "        #the final step of the proposed layer estimates the temporal mapping W2, after the bias shift (11)\n",
        "        y = X @ self.W2 + self.B\n",
        "        return y\n",
        "\n",
        "class BL_layer(nn.Module):\n",
        "  def __init__(self, d2, d1, t1, t2):\n",
        "        super().__init__()\n",
        "        weight1 = torch.Tensor(d2, d1)\n",
        "        self.W1 = nn.Parameter(weight1)\n",
        "        nn.init.kaiming_uniform_(self.W1, nonlinearity='relu')\n",
        "\n",
        "        weight2 = torch.Tensor(t1, t2)\n",
        "        self.W2 = nn.Parameter(weight2)\n",
        "        nn.init.kaiming_uniform_(self.W2, nonlinearity='relu')\n",
        "\n",
        "        bias1 = torch.zeros((d2, t2))\n",
        "        self.B = nn.Parameter(bias1)\n",
        "        nn.init.constant_(self.B, 0)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.activation(self.W1 @ x @ self.W2 + self.B)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inSLg97R6p3k"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BiN(nn.Module):\n",
        "    def __init__(self, d2, d1, t1, t2):\n",
        "        super().__init__()\n",
        "        self.t1 = t1\n",
        "        self.d1 = d1\n",
        "        self.t2 = t2\n",
        "        self.d2 = d2\n",
        "\n",
        "        bias1 = torch.Tensor(t1, 1)\n",
        "        self.B1 = nn.Parameter(bias1)\n",
        "        nn.init.constant_(self.B1, 0)\n",
        "\n",
        "        l1 = torch.Tensor(t1, 1)\n",
        "        self.l1 = nn.Parameter(l1)\n",
        "        nn.init.xavier_normal_(self.l1)\n",
        "\n",
        "        bias2 = torch.Tensor(d1, 1)\n",
        "        self.B2 = nn.Parameter(bias2)\n",
        "        nn.init.constant_(self.B2, 0)\n",
        "\n",
        "        l2 = torch.Tensor(d1, 1)\n",
        "        self.l2 = nn.Parameter(l2)\n",
        "        nn.init.xavier_normal_(self.l2)\n",
        "\n",
        "        y1 = torch.Tensor(1, )\n",
        "        self.y1 = nn.Parameter(y1)\n",
        "        nn.init.constant_(self.y1, 0.5)\n",
        "\n",
        "        y2 = torch.Tensor(1, )\n",
        "        self.y2 = nn.Parameter(y2)\n",
        "        nn.init.constant_(self.y2, 0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # if the two scalars are negative then we setting them to 0\n",
        "        if (self.y1[0] < 0):\n",
        "            y1 = torch.cuda.FloatTensor(1, )\n",
        "            self.y1 = nn.Parameter(y1)\n",
        "            nn.init.constant_(self.y1, 0.01)\n",
        "\n",
        "        if (self.y2[0] < 0):\n",
        "            y2 = torch.cuda.FloatTensor(1, )\n",
        "            self.y2 = nn.Parameter(y2)\n",
        "            nn.init.constant_(self.y2, 0.01)\n",
        "\n",
        "        # normalization along the temporal dimensione\n",
        "        T2 = torch.ones([self.t1, 1], device=device)\n",
        "        x2 = torch.mean(x, dim=2)\n",
        "        x2 = torch.reshape(x2, (x2.shape[0], x2.shape[1], 1))\n",
        "        \n",
        "        std = torch.std(x, dim=2)\n",
        "        std = torch.reshape(std, (std.shape[0], std.shape[1], 1))\n",
        "        # it can be possible that the std of some temporal slices is 0, and this produces inf values, so we have to set them to one\n",
        "        std[std < 1e-4] = 1\n",
        "\n",
        "        diff = x - (x2 @ (T2.T))\n",
        "        Z2 = diff / (std @ (T2.T))\n",
        "\n",
        "        X2 = self.l2 @ T2.T\n",
        "        X2 = X2 * Z2\n",
        "        X2 = X2 + (self.B2 @ T2.T)\n",
        "\n",
        "        # normalization along the feature dimension\n",
        "        T1 = torch.ones([self.d1, 1], device=device)\n",
        "        x1 = torch.mean(x, dim=1)\n",
        "        x1 = torch.reshape(x1, (x1.shape[0], x1.shape[1], 1))\n",
        "\n",
        "        std = torch.std(x, dim=1)\n",
        "        std = torch.reshape(std, (std.shape[0], std.shape[1], 1))\n",
        "\n",
        "        op1 = x1 @ T1.T\n",
        "        op1 = torch.permute(op1, (0, 2, 1))\n",
        "\n",
        "        op2 = std @ T1.T\n",
        "        op2 = torch.permute(op2, (0, 2, 1))\n",
        "\n",
        "        z1 = (x - op1) / (op2)\n",
        "        X1 = (T1 @ self.l1.T)\n",
        "        X1 = X1 * z1\n",
        "        X1 = X1 + (T1 @ self.B1.T)\n",
        "\n",
        "        # weighing the imporance of temporal and feature normalization\n",
        "        x = self.y1 * X1 + self.y2 * X2\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Bl1PlKiV5A"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGQzinO66jNp"
      },
      "outputs": [],
      "source": [
        "class BiN_BTABL(nn.Module):\n",
        "  def __init__(self, d2, d1, t1, t2, d3, t3):\n",
        "    super().__init__()\n",
        "\n",
        "    self.BiN = BiN(d2, d1, t1, t2)\n",
        "    self.BL = BL_layer(d2, d1, t1, t2)\n",
        "    self.TABL = TABL_layer(d3, d2, t2, t3)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #first of all we pass the input to the BiN layer, then we use the B(TABL) architecture\n",
        "    x = self.BiN(x)\n",
        "\n",
        "    self.max_norm_(self.BL.W1.data)\n",
        "    self.max_norm_(self.BL.W2.data)\n",
        "    x = self.BL(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    self.max_norm_(self.TABL.W1.data)\n",
        "    self.max_norm_(self.TABL.W.data)\n",
        "    self.max_norm_(self.TABL.W2.data)\n",
        "    x = self.TABL(x)\n",
        "    x = torch.squeeze(x)\n",
        "    x = torch.softmax(x, 1)\n",
        "\n",
        "\n",
        "    return x\n",
        "\n",
        "  def max_norm_(self, w):\n",
        "    with torch.no_grad():\n",
        "      if (torch.linalg.matrix_norm(w) > 10.0):\n",
        "        norm = torch.linalg.matrix_norm(w)\n",
        "        desired = torch.clamp(norm, min=0.0, max=10.0)\n",
        "        w *= (desired / (1e-8 + norm))\n",
        "\n",
        "\n",
        "class BiN_CTABL(nn.Module):\n",
        "  def __init__(self, d2, d1, t1, t2, d3, t3, d4, t4):\n",
        "    super().__init__()\n",
        "\n",
        "    self.BiN = BiN(d2, d1, t1, t2)\n",
        "    self.BL = BL_layer(d2, d1, t1, t2)\n",
        "    self.BL2 = BL_layer(d3, d2, t2, t3)\n",
        "    self.TABL = TABL_layer(d4, d3, t3, t4)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #first of all we pass the input to the BiN layer, then we use the C(TABL) architecture\n",
        "    x = self.BiN(x)\n",
        "\n",
        "    self.max_norm_(self.BL.W1.data)\n",
        "    self.max_norm_(self.BL.W2.data)\n",
        "    x = self.BL(x)\n",
        "    x = self.dropout(x)\n",
        "    \n",
        "    self.max_norm_(self.BL2.W1.data)\n",
        "    self.max_norm_(self.BL2.W2.data)\n",
        "    x = self.BL2(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    self.max_norm_(self.TABL.W1.data)\n",
        "    self.max_norm_(self.TABL.W.data)\n",
        "    self.max_norm_(self.TABL.W2.data)\n",
        "    x = self.TABL(x)\n",
        "    x = torch.squeeze(x)\n",
        "    x = torch.softmax(x, 1)\n",
        "    \n",
        "    return x\n",
        "\n",
        "  def max_norm_(self, w):\n",
        "    with torch.no_grad():\n",
        "      if (torch.linalg.matrix_norm(w) > 10.0):\n",
        "        norm = torch.linalg.matrix_norm(w)\n",
        "        desired = torch.clamp(norm, min=0.0, max=10.0)\n",
        "        w *= (desired / (1e-8 + norm))   \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bejZgDmCkkHi"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_u5esKfTT-S"
      },
      "outputs": [],
      "source": [
        "#you can choose between the two architectures\n",
        "\n",
        "#model = BiN_BTABL(120, 40, 10, 5, 3, 1)\n",
        "model = BiN_CTABL(60, 40, 10, 10, 120, 5, 3, 1)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=1e-3)\n",
        "\n",
        "\n",
        "def batch_gd(model, criterion, optimizer, epochs):\n",
        "    \n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "    best_test_loss = np.inf\n",
        "    best_test_epoch = 0\n",
        "    \n",
        "    for it in tqdm(range(epochs)):\n",
        "        \n",
        "        #as written in the paper we change the lr at the 11 and 71 epochs\n",
        "        if (it == 10):\n",
        "              for g in optimizer.param_groups:\n",
        "                g['lr'] = 0.0001\n",
        "\n",
        "        if (it == 70):\n",
        "          for g in optimizer.param_groups:\n",
        "                g['lr'] = 0.00001\n",
        "\n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "        for inputs, targets in train_loader:\n",
        "\n",
        "            # move data to GPU\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            #computing the error\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "            \n",
        "        # Get train loss and test loss\n",
        "        train_loss = np.mean(train_loss)\n",
        "        model.eval()\n",
        "        \n",
        "        test_loss = []\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss.append(loss.item())\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "        \n",
        "        #We save the best model\n",
        "        if test_loss < best_test_loss:\n",
        "            torch.save(model, '/best_model_BiNCTABL')\n",
        "            best_test_loss = test_loss\n",
        "            best_test_epoch = it\n",
        "            print('model saved')\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
        "        \n",
        "    #torch.save(model, '/content/drive/MyDrive/Output/best_model_translob_FI')\n",
        "    return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x9vq-ZAzTb6K",
        "outputId": "789502ba-c3f3-4b33-d82d-b713ff97eb1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------- List Hyper Parameters -------\n",
            "epochs   ->   200\n",
            "learningRate   ->   0.001\n",
            "horizon    ->     50\n",
            "batch size   ->    256\n",
            "Optimizer   ->    Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.001\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/200 [18:50<62:30:37, 1130.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 1/200, Train Loss: 0.7595,           Validation Loss: 0.6863, Duration: 0:18:50.843132, Best Val Epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/200 [37:38<62:04:59, 1128.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 2/200, Train Loss: 0.6940,           Validation Loss: 0.6841, Duration: 0:18:47.341088, Best Val Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 3/200 [56:22<61:40:03, 1126.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 3/200, Train Loss: 0.6919,           Validation Loss: 0.6832, Duration: 0:18:44.697621, Best Val Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 4/200 [1:15:06<61:16:33, 1125.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 4/200, Train Loss: 0.6908,           Validation Loss: 0.6824, Duration: 0:18:43.256918, Best Val Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 5/200 [1:33:55<61:02:05, 1126.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 5/200, Train Loss: 0.6901,           Validation Loss: 0.6817, Duration: 0:18:49.133734, Best Val Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 6/200 [1:52:46<60:47:43, 1128.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/200, Train Loss: 0.6896,           Validation Loss: 0.6817, Duration: 0:18:50.805675, Best Val Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 7/200 [2:11:36<60:31:39, 1129.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 7/200, Train Loss: 0.6894,           Validation Loss: 0.6809, Duration: 0:18:50.760190, Best Val Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 8/200 [2:30:27<60:14:33, 1129.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/200, Train Loss: 0.6895,           Validation Loss: 0.6815, Duration: 0:18:50.701910, Best Val Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 9/200 [2:49:14<59:52:44, 1128.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/200, Train Loss: 0.6891,           Validation Loss: 0.6822, Duration: 0:18:46.538233, Best Val Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 10/200 [3:08:01<59:32:50, 1128.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/200, Train Loss: 0.6893,           Validation Loss: 0.6815, Duration: 0:18:47.485929, Best Val Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 11/200 [3:27:04<59:28:24, 1132.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 11/200, Train Loss: 0.6880,           Validation Loss: 0.6805, Duration: 0:19:03.180409, Best Val Epoch: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 12/200 [3:46:02<59:14:19, 1134.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 12/200, Train Loss: 0.6878,           Validation Loss: 0.6805, Duration: 0:18:57.856168, Best Val Epoch: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 13/200 [4:05:13<59:10:34, 1139.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/200, Train Loss: 0.6877,           Validation Loss: 0.6805, Duration: 0:19:10.401246, Best Val Epoch: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 14/200 [4:24:29<59:07:51, 1144.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/200, Train Loss: 0.6878,           Validation Loss: 0.6805, Duration: 0:19:16.593275, Best Val Epoch: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 15/200 [4:44:04<59:16:58, 1153.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/200, Train Loss: 0.6877,           Validation Loss: 0.6807, Duration: 0:19:34.804892, Best Val Epoch: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 16/200 [5:03:59<59:35:32, 1165.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 16/200, Train Loss: 0.6878,           Validation Loss: 0.6804, Duration: 0:19:54.559680, Best Val Epoch: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 17/200 [5:24:04<59:52:25, 1177.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/200, Train Loss: 0.6877,           Validation Loss: 0.6805, Duration: 0:20:05.532197, Best Val Epoch: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 18/200 [5:44:06<59:55:13, 1185.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/200, Train Loss: 0.6878,           Validation Loss: 0.6805, Duration: 0:20:02.446559, Best Val Epoch: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 18/200 [6:01:43<60:57:27, 1205.76s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-eedd8734e6a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Optimizer   ->    \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m train_losses, val_losses = batch_gd(model, criterion, optimizer, \n\u001b[0m\u001b[1;32m     11\u001b[0m                                      epochs)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4ddc0d8c7e0d>\u001b[0m in \u001b[0;36mbatch_gd\u001b[0;34m(model, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;31m#outputs = torch.squeeze(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-d7460bdaae2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBiN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#print(x[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-438638432d9b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mZ2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m           \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mZ2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"------- List Hyper Parameters -------\")\n",
        "print(\"epochs   ->   \" + str(epochs))\n",
        "print(\"learningRate   ->   \" + str(lr))\n",
        "print(\"horizon    ->     \" + str(T))\n",
        "print(\"batch size   ->    \" + str(batch_size))\n",
        "print(\"Optimizer   ->    \" + str(optimizer))\n",
        "\n",
        "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
        "                                     epochs)\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7CF2CwUkn4G"
      },
      "source": [
        "### **Model Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFg5d6CzTgWS",
        "outputId": "29e3eed7-7d95-4006-cbde-ff2d4e164b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.8810\n"
          ]
        }
      ],
      "source": [
        "model = torch.load('/best_model_BiNCTABL')\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "all_targets = []\n",
        "all_predictions = []\n",
        "\n",
        "for inputs, targets in test_loader:\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    #outputs = torch.squeeze(outputs)\n",
        "    # Get prediction\n",
        "    # torch.max returns both max and argmax\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    # update counts\n",
        "    n_correct += (predictions == targets).sum().item()\n",
        "    n_total += targets.shape[0]\n",
        "\n",
        "    all_targets.append(targets.cpu().numpy())\n",
        "    all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "print(f\"Test acc: {test_acc:.4f}\")\n",
        "  \n",
        "all_targets = np.concatenate(all_targets)    \n",
        "all_predictions = np.concatenate(all_predictions)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oOu5lwf6zw0",
        "outputId": "ce465ea5-c931-461f-96de-e05aef8e905b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy_score: 0.8810085045101846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9204    0.8194    0.8669     38464\n",
            "           1     0.8480    0.9528    0.8974     65997\n",
            "           2     0.9163    0.8136    0.8619     35112\n",
            "\n",
            "    accuracy                         0.8810    139573\n",
            "   macro avg     0.8949    0.8619    0.8754    139573\n",
            "weighted avg     0.8851    0.8810    0.8800    139573\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
        "print(classification_report(all_targets, all_predictions, digits=4))\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "c = confusion_matrix(all_targets, all_predictions, normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(c)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
